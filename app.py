#!/usr/bin/env python3
"""
Manga Translator App - Main Gradio Interface
============================================

A comprehensive manga/comic translation application that:
- Detects text bubbles using YOLO model
- Extracts text using multi-language OCR engines
- Translates text using various translation services
- Replaces original text with translated text

Author: MangaTranslator Team
License: MIT
"""

# Core modules
from add_text import add_text
from detect_bubbles import detect_bubbles
from process_bubble import process_bubble
from translator import MangaTranslator
from multi_ocr import MultiLanguageOCR

# External libraries
from ultralytics import YOLO
from PIL import Image
import gradio as gr
import numpy as np
import cv2
import os
import tempfile
import time
import atexit
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Debug cleanup function
def cleanup_debug_files():
    """Clean up temporary debug files on exit"""
    debug_dir = os.path.join(tempfile.gettempdir(), "manga_translator_debug")
    if os.path.exists(debug_dir):
        try:
            import shutil
            shutil.rmtree(debug_dir)
            print(f"üßπ Cleaned up debug directory: {debug_dir}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not clean debug directory: {e}")

# Register cleanup function to run on exit
atexit.register(cleanup_debug_files)

# Configuration constants
MODEL = "model.pt"  # YOLO model for bubble detection
EXAMPLE_LIST = [["examples/0.png"], ["examples/ex0.png"]]  # Example images for testing

# UI Configuration
TITLE = "Multi-Language Comic Translator with AI"
DESCRIPTION = """
üåç **D·ªãch truy·ªán tranh ƒëa ng√¥n ng·ªØ sang ti·∫øng Vi·ªát!**

**üìö OCR Engine t·ªëi ∆∞u:**
- üáØüáµ ** (Nh·∫≠t):** manga-ocr (chuy√™n bi·ªát)
- üá®üá≥ **Manhua (Trung):** PaddleOCR (t·ªëi ∆∞u Chinese)  
- üá∞üá∑ **Manhwa (H√†n):** EasyOCR (h·ªó tr·ª£ Korean t·ªët)
- üá∫üá∏ **Comics (Anh):** EasyOCR (ƒëa ng√¥n ng·ªØ)

**ü§ñ AI Translation:** Gemini 2.0 Flash v·ªõi prompt t·ªëi ∆∞u cho t·ª´ng lo·∫°i truy·ªán

**üé® NEW: T√πy ch·ªânh phong c√°ch d·ªãch:**
- Prompt t·ª± ƒë·ªông th√¥ng minh theo ng√¥n ng·ªØ
- T√πy ch·ªânh phong c√°ch: nh·∫π nh√†ng, trang tr·ªçng, tr·∫ª trung...
- Font size t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh theo k√≠ch th∆∞·ªõc bubble
"""


def predict(img, translation_method, font_path, source_language="auto", gemini_api_key=None, custom_prompt=None):
    """
    Main prediction function for manga translation
    
    Args:
        img: Input image (PIL Image)
        translation_method: Translation service to use
        font_path: Path to font file for text rendering
        source_language: Source language code or 'auto' for auto-detection
        gemini_api_key: Optional Gemini API key
        custom_prompt: Custom translation style prompt or None for auto
    
    Returns:
        PIL Image: Translated image with text replaced
    """
    # Set default values if None
    if translation_method is None:
        translation_method = "google"
    if font_path is None:
        font_path = "fonts/animeace_i.ttf"

    # Handle API key - use from input or environment variable
    if not gemini_api_key or gemini_api_key.strip() == "":
        gemini_api_key = os.getenv("GEMINI_API_KEY", None)
    
    # Handle custom prompt
    if custom_prompt and custom_prompt.strip():
        print(f"üé® Using custom prompt: {custom_prompt[:50]}{'...' if len(custom_prompt) > 50 else ''}")
    else:
        custom_prompt = None
        print("ü§ñ Using automatic prompt based on source language")
    
    # Debug logging
    print(f"Using translation method: {translation_method}")
    print(f"Source language: {source_language}")
    print(f"API key available: {'Yes' if gemini_api_key else 'No'}")
    if gemini_api_key:
        print(f"API key preview: {gemini_api_key[:10]}...")

    # Step 1: Detect text bubbles using YOLO model
    results = detect_bubbles(MODEL, img)
    print(f"üéØ Detected {len(results)} bubbles")
    
    # Debug: Print all bubble coordinates
    for idx, result in enumerate(results):
        x1, y1, x2, y2, score, class_id = result
        print(f"   Bubble {idx+1}: ({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f}) - Score: {score:.3f}")
    
    # Sort bubbles by Y coordinate (top to bottom) to ensure consistent processing order
    results = sorted(results, key=lambda x: x[1])  # Sort by y1 (top coordinate)
    print(f"üìã Processing order (sorted by Y):")
    for idx, result in enumerate(results):
        x1, y1, x2, y2, score, class_id = result
        print(f"   Order {idx+1}: ({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})")

    # Step 2: Initialize translator with optional Gemini API key
    manga_translator = MangaTranslator(gemini_api_key=gemini_api_key)
    
    # Step 3: Initialize multi-language OCR system
    multi_ocr = MultiLanguageOCR()
    
    # Show OCR recommendation for selected language
    ocr_method, ocr_desc = multi_ocr.get_best_ocr_for_language(source_language)
    print(f"üîç OCR Engine: {ocr_desc}")

    # Convert PIL image to numpy array for processing
    original_image = np.array(img)  # Keep original unchanged
    image = original_image.copy()   # Working copy for modifications

    # Step 4: Process each detected bubble
    for idx, result in enumerate(results):
        x1, y1, x2, y2, score, class_id = result
        print(f"üîÑ Processing bubble {idx+1}/{len(results)} at coordinates ({x1}, {y1}, {x2}, {y2})")

        # Extract the bubble region from ORIGINAL image (not modified one)
        detected_image = original_image[int(y1):int(y2), int(x1):int(x2)]
        print(f"üìä OCR source image shape: {detected_image.shape}, dtype: {detected_image.dtype}, range: [{detected_image.min()}, {detected_image.max()}]")

        # Convert to PIL Image for OCR processing (fix the scaling issue)
        im = Image.fromarray(np.uint8(detected_image))
        
        # Optional debug mode - only save if DEBUG environment variable is set
        if os.getenv("MANGA_DEBUG", "").lower() in ("1", "true", "yes"):
            import tempfile
            import time
            timestamp = int(time.time())
            debug_dir = os.path.join(tempfile.gettempdir(), "manga_translator_debug")
            os.makedirs(debug_dir, exist_ok=True)
            debug_filename = os.path.join(debug_dir, f"bubble_{timestamp}_{idx+1}.png")
            im.save(debug_filename)
            print(f"ÔøΩ DEBUG: Saved OCR input to {debug_filename}")
        
        # Step 5: Extract text using appropriate OCR engine
        text = multi_ocr.extract_text(im, source_language, method="auto")
        
        # Clean OCR text before translation
        text = text.strip() if text else ""
        
        # Debug logging for OCR results
        print(f"üìù OCR Text (raw): '{text}'")
        print(f"üìù OCR Text (length): {len(text)}")
        print(f"üìù OCR Text (repr): {repr(text)}")

        # Step 6: Process the bubble for text replacement (from working copy)
        working_bubble = image[int(y1):int(y2), int(x1):int(x2)]
        processed_bubble, cont = process_bubble(working_bubble)

        # Step 7: Translate the extracted text
        if text:  # Only translate if text exists
            text_translated = manga_translator.translate(text,
                                                         method=translation_method,
                                                         source_lang=source_language,
                                                         custom_prompt=custom_prompt)
            print(f"üåè Translated: '{text_translated}'")
        else:
            text_translated = ""
            print("‚ö†Ô∏è No text detected, skipping translation")

        # Step 8: Add translated text back to the image
        print(f"üìù Adding text to bubble {idx+1}: '{text_translated[:50]}{'...' if len(text_translated) > 50 else ''}'")
        image[int(y1):int(y2), int(x1):int(x2)] = add_text(processed_bubble, text_translated, font_path, cont)

    return Image.fromarray(image)


# Create Gradio interface
demo = gr.Interface(
    fn=predict,
    inputs=[
        # Input image
        "image",
        
        # Translation method dropdown
        gr.Dropdown([("Google Translate", "google"),
                     ("Gemini AI (Khuy·∫øn ngh·ªã)", "gemini"),
                     ("Helsinki-NLP (Nh·∫≠t‚ÜíAnh)", "hf"),
                     ("Sogou", "sogou"),
                     ("Bing", "bing")],
                    label="Ph∆∞∆°ng th·ª©c d·ªãch",
                    value="gemini"),
        
        # Font selection dropdown
        gr.Dropdown([("animeace_i", "fonts/animeace_i.ttf"),
                     ("animeace2_reg", "fonts/animeace2_reg.ttf"),
                     ("mangati", "fonts/mangati.ttf"),
                     ("ariali", "fonts/ariali.ttf")],
                    label="Font ch·ªØ",
                    value="fonts/animeace_i.ttf"),
        
        # Source language dropdown
        gr.Dropdown([("T·ª± ƒë·ªông nh·∫≠n di·ªán", "auto"),
                     ("Ti·∫øng Nh·∫≠t (Manga)", "ja"),
                     ("Ti·∫øng Trung (Manhua)", "zh"),
                     ("Ti·∫øng H√†n (Manhwa)", "ko"),
                     ("Ti·∫øng Anh", "en")],
                    label="Ng√¥n ng·ªØ g·ªëc",
                    value="auto"),
        
        # API key input
        gr.Textbox(label="Gemini API Key (T√πy ch·ªçn)", 
                   type="password", 
                   placeholder="Nh·∫≠p API key ƒë·ªÉ d·ªãch AI th√¥ng minh",
                   value=os.getenv("GEMINI_API_KEY", "")),
        
        # Custom prompt input
        gr.Textbox(label="üé® Prompt T√πy Ch·ªânh (Advanced)", 
                   lines=4,
                   placeholder="""V√≠ d·ª•:
- D·ªãch theo phong c√°ch nh·∫π nh√†ng, th√¢n thi·ªán
- Gi·ªØ nguy√™n t√≠nh c√°ch nh√¢n v·∫≠t, s·ª≠ d·ª•ng ng√¥n ng·ªØ tr·∫ª trung
- D·ªãch theo phong c√°ch c·ªï ƒëi·ªÉn, trang tr·ªçng
- D·ªãch ng·∫Øn g·ªçn ƒë·ªÉ v·ª´a bubble
- ƒê·ªÉ tr·ªëng = s·ª≠ d·ª•ng prompt t·ª± ƒë·ªông theo ng√¥n ng·ªØ""",
                   value="")
    ],
    outputs=[gr.Image()],
    examples=EXAMPLE_LIST,
    title=TITLE,
    description=DESCRIPTION
)


# Launch the application
if __name__ == "__main__":
    demo.launch(debug=False, share=False)
