#!/usr/bin/env python3
"""
Enhanced Manga Translator Module
===============================

A comprehensive translation system for manga/comic text with context-aware AI translation.

üÜï NEW FEATURES:
- Context metadata support for smart pronoun/honorific selection
- Locked output format (translation only - no explanations)  
- Language-specific rules for JA/ZH/KO comics
- SFX and thought bubble specialized handling
- Bubble fitting with character limits
- Line preservation for multi-bubble text

Features:
- Multiple translation backends (Google, Gemini AI, HuggingFace, Sogou, Bing)
- Context-aware translation with relationship/formality/gender metadata
- Language-specific prompts (Japanese manga, Chinese manhua, Korean manhwa)
- Clean output guarantee (no AI explanations or multiple options)
- Automatic language detection
- Error handling and fallbacks

Author: MangaTranslator Team  
License: MIT
Version: 2.0 (Enhanced Prompt System)
"""

# Translation libraries
from deep_translator import GoogleTranslator
from transformers import pipeline
import translators as ts

# Standard library imports
import requests
import random
import time
import os
import json


class MangaTranslator:
    """
    Multi-service translator optimized for manga/comic text translation with context awareness.
    
    üÜï NEW: Context metadata support for intelligent translation:
    - Smart pronoun/honorific selection based on relationship and formality
    - Gender-aware translation for natural Vietnamese output  
    - Bubble fitting with character limits
    - SFX and internal thought specialized handling
    - Clean output guarantee (no AI explanations)
    """
    
    def __init__(self, gemini_api_key=None):
        """
        Initialize the translator with optional Gemini API key
        
        Args:
            gemini_api_key (str, optional): Gemini API key for AI translation
        """
        self.target = "vi"  # Target language: Vietnamese
        
        # Supported source languages mapping
        self.supported_languages = {
            "auto": "T·ª± ƒë·ªông nh·∫≠n di·ªán",
            "ja": "Ti·∫øng Nh·∫≠t (Manga)",
            "zh": "Ti·∫øng Trung (Manhua)", 
            "ko": "Ti·∫øng H√†n (Manhwa)",
            "en": "Ti·∫øng Anh"
        }
        
        # Initialize Gemini API key
        if not gemini_api_key:
            gemini_api_key = os.getenv("GEMINI_API_KEY")
        
        if gemini_api_key and gemini_api_key.strip():
            self.gemini_api_key = gemini_api_key.strip()
            print(f"‚úÖ Gemini 2.0 Flash API key configured: {self.gemini_api_key[:10]}...")
        else:
            self.gemini_api_key = None
            print("‚ö†Ô∏è No Gemini API key provided")
            
        # Translation methods mapping
        self.translators = {
            "google": self._translate_with_google,
            "hf": self._translate_with_hf,
            "sogou": self._translate_with_sogou,
            "bing": self._translate_with_bing,
            "gemini": self._translate_with_gemini
        }

    def translate(self, text, method="google", source_lang="auto", context=None, custom_prompt=None):
        """
        Translate text to Vietnamese using the specified method with context support
        
        Args:
            text (str): Text to translate
            method (str): Translation method ("google", "gemini", "hf", "sogou", "bing")
            source_lang (str): Source language code - "auto", "ja", "zh", "ko", "en"
            context (dict, optional): Context metadata for better translation:
                - gender: 'male'/'female'/'neutral' (default: 'neutral')
                - relationship: 'friend'/'senior'/'junior'/'family'/'stranger' (default: 'neutral') 
                - formality: 'casual'/'polite'/'formal' (default: 'casual')
                - bubble_limit: int (character limit for bubble fitting)
                - is_thought: bool (internal monologue/thought bubble)
                - is_sfx: bool (sound effect)
                - scene_context: str (brief scene description)
            custom_prompt (str, optional): Custom translation style prompt to override defaults
            
        Returns:
            str: Translated text in Vietnamese
        """
        
        if method == "gemini" and not self.gemini_api_key:
            print("‚ö†Ô∏è Gemini 2.0 Flash API not available, falling back to Google Translate")
            method = "google"
        elif method == "gemini" and self.gemini_api_key:
            print("ü§ñ Using Gemini 2.0 Flash for context-aware translation")
            
        translator_func = self.translators.get(method)

        if translator_func:
            if method == "gemini":
                return translator_func(self._preprocess_text(text), source_lang, context, custom_prompt)
            else:
                return translator_func(self._preprocess_text(text), source_lang)
        else:
            raise ValueError("Invalid translation method.")
            
    def _translate_with_google(self, text, source_lang="auto"):
        self._delay()
        
        # Map our language codes to Google's codes
        google_lang = source_lang
        if source_lang == "zh":
            google_lang = "zh-cn"
        
        translator = GoogleTranslator(source=google_lang, target=self.target)
        translated_text = translator.translate(text)
        return translated_text if translated_text is not None else text

    def _translate_with_hf(self, text, source_lang="auto"):
        # HF pipeline ch·ªâ h·ªó tr·ª£ Japanese to English, fallback to Google
        print("‚ö†Ô∏è Helsinki-NLP ch·ªâ h·ªó tr·ª£ Nh·∫≠t ‚Üí Anh, chuy·ªÉn sang Google Translate")
        return self._translate_with_google(text, source_lang)

    def _translate_with_sogou(self, text, source_lang="auto"):
        self._delay()
        
        # Map to sogou language codes
        sogou_lang = "auto" if source_lang == "auto" else source_lang
        
        translated_text = ts.translate_text(text, translator="sogou",
                                            from_language=sogou_lang,
                                            to_language=self.target)
        return translated_text if translated_text is not None else text

    def _translate_with_bing(self, text, source_lang="auto"):
        self._delay()
        
        # Map to bing language codes  
        bing_lang = "auto" if source_lang == "auto" else source_lang
        
        translated_text = ts.translate_text(text, translator="bing",
                                            from_language=bing_lang, 
                                            to_language=self.target)
        return translated_text if translated_text is not None else text

    def _translate_with_gemini(self, text, source_lang="auto", context=None, custom_prompt=None):
        """
        Translate using Google Gemini 2.0 Flash with context metadata support.
        
        Args:
            text (str): Text to translate
            source_lang (str): Source language
            context (dict, optional): Context metadata with keys:
                - gender: 'male'/'female'/'neutral'
                - relationship: 'friend'/'senior'/'junior'/'family'/'stranger'
                - formality: 'casual'/'polite'/'formal'
                - bubble_limit: int (character limit)
                - is_thought: bool (internal monologue)
                - is_sfx: bool (sound effect)
                - scene_context: str (brief scene description)
        """
        if not self.gemini_api_key:
            raise ValueError("Gemini API key not configured")
        
        # Clean input text
        text = text.strip() if text else ""
        if not text:
            print("‚ö†Ô∏è Empty text sent to Gemini, skipping")
            return ""
            
        # Debug logging
        print(f"ü§ñ Gemini input: '{text}' | Lang: {source_lang}")
        if context:
            print(f"üìã Context: {context}")
            
        try:
            # Use REST API directly for more reliable connection
            url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
            
            headers = {
                'Content-Type': 'application/json',
                'X-goog-api-key': self.gemini_api_key
            }
            
            # Get specialized prompt based on source language and context
            prompt = self._get_translation_prompt(text, source_lang, context, custom_prompt)
            
            data = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.3,
                    "maxOutputTokens": 200,
                    "topP": 0.9,
                    "topK": 40
                }
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    translated_text = result['candidates'][0]['content']['parts'][0]['text'].strip()
                    
                    # Aggressive cleanup - remove any AI explanations
                    translated_text = self._clean_gemini_response(translated_text)
                    
                    return translated_text if translated_text else text
                else:
                    print("‚ùå No translation candidates in response")
                    return self._translate_with_google(text, source_lang)
            else:
                print(f"‚ùå Gemini API error: {response.status_code} - {response.text}")
                return self._translate_with_google(text, source_lang)
            
        except Exception as e:
            print(f"Gemini translation failed: {e}")
            # Fallback to Google Translate
            return self._translate_with_google(text, source_lang)

    def _get_translation_prompt(self, text, source_lang, context=None, custom_prompt=None):
        """
        Generate enhanced translation prompt with context metadata support
        """
        # If custom prompt provided, use it directly
        if custom_prompt and custom_prompt.strip():
            return f"""B·∫°n l√† m·ªôt chuy√™n gia d·ªãch thu·∫≠t manga/comic chuy√™n nghi·ªáp. H√£y d·ªãch text sau sang ti·∫øng Vi·ªát theo y√™u c·∫ßu:

{custom_prompt.strip()}

Text c·∫ßn d·ªãch: "{text}"

CH·ªà tr·∫£ v·ªÅ b·∫£n d·ªãch ti·∫øng Vi·ªát, kh√¥ng gi·∫£i th√≠ch g√¨ th√™m."""
        
        # Use default prompt system
        # Parse context metadata
        gender = context.get('gender', 'neutral') if context else 'neutral'
        relationship = context.get('relationship', 'neutral') if context else 'neutral'  
        formality = context.get('formality', 'casual') if context else 'casual'
        bubble_limit = context.get('bubble_limit', None) if context else None
        is_thought = context.get('is_thought', False) if context else False
        is_sfx = context.get('is_sfx', False) if context else False
        scene_context = context.get('scene_context', '') if context else ''
        
        # Build context info
        context_info = []
        if gender != 'neutral':
            context_info.append(f"GENDER: {gender}")
        if relationship != 'neutral':
            context_info.append(f"RELATIONSHIP: {relationship}")
        if formality != 'casual':
            context_info.append(f"FORMALITY: {formality}")
        if bubble_limit:
            context_info.append(f"BUBBLE_LIMIT: {bubble_limit} chars")
        if is_thought:
            context_info.append("TYPE: internal_thought")
        if is_sfx:
            context_info.append("TYPE: sound_effect")
        if scene_context:
            context_info.append(f"SCENE: {scene_context}")
            
        context_str = " | ".join(context_info) if context_info else "No specific context"
        
        # Get language-specific rules
        lang_rules = self._get_language_rules(source_lang)
        
        return f"""D·ªãch "{text}" sang ti·∫øng Vi·ªát.

CONTEXT: {context_str}

{lang_rules}

GLOBAL RULES:
- Ch·ªâ tr·∫£ v·ªÅ chu·ªói b·∫£n d·ªãch, kh√¥ng nh√£n, kh√¥ng ngo·∫∑c k√©p, kh√¥ng gi·∫£i th√≠ch
- M·ªôt d√≤ng v√†o ‚Üí m·ªôt d√≤ng ra (b·∫£o to√†n s·ªë d√≤ng)
- X∆∞ng h√¥ t·ª± ƒë·ªông theo relationship/formality: b·∫°n b√®‚Üí"t√¥i/c·∫≠u"; l·ªãch s·ª±‚Üí"t√¥i/anh(ch·ªã)"; th√¢n m·∫≠t‚Üí"tao/m√†y"
- Kh√¥ng s√°ng t√°c th√™m, d·ªãch trung th·ª±c nh∆∞ng m∆∞·ª£t
- T√™n ri√™ng/k√Ω hi·ªáu: gi·ªØ nguy√™n
- D·∫•u c√¢u Vi·ªát: "‚Ä¶" cho th·ªü d√†i, "‚Äî" cho ng·∫Øt m·∫°nh
- SFX: d·ªãch ng·∫Øn m·∫°nh (vd: "R·∫¶M!", "B·ª§P!")
- Thought: d√πng "‚Ä¶" m·ªÅm, tr√°nh ƒë·∫°i t·ª´ n·∫∑ng
- Bubble fit: ∆∞u ti√™n c√¢u ng·∫Øn t·ª± nhi√™n

CH·ªà TR·∫¢ V·ªÄ B·∫¢N D·ªäCH:"""
    def _get_language_rules(self, source_lang):
        """Get language-specific translation rules"""
        if source_lang == "ja":
            return """JA RULES:
- Keigo‚Üí"·∫°/d·∫°"; th∆∞·ªùng‚Üíb·ªè k√≠nh ng·ªØ
- Senpai/kouhai‚Üí"ti·ªÅn b·ªëi/h·∫≠u b·ªëi" ho·∫∑c gi·ªØ nguy√™n
- „ÇÑ„Å∞„ÅÑ‚Üí"Ch·∫øt ti·ªát!/T·ªá r·ªìi!"; „Åô„Åî„ÅÑ‚Üí"ƒê·ªânh qu√°!"  
- ÊäÄ‚Üí"k·ªπ thu·∫≠t/chi√™u"; ÂøÖÊÆ∫ÊäÄ‚Üí"tuy·ªát k·ªπ"; Â§âË∫´‚Üí"bi·∫øn h√¨nh"
- SFX: „Éê„É≥‚Üí"B√ôNG!"; „Éâ„É≥‚Üí"R·∫¶M!"; „Ç≠„É©„Ç≠„É©‚Üí"l·∫•p l√°nh" """

        elif source_lang == "zh":
            return """ZH RULES:
- ÊÇ®‚Üí"Ng√†i/th∆∞a"; ‰Ω†‚Üí"anh/ch·ªã"; Êúï‚Üí"Tr·∫´m"; Êú¨Áéã‚Üí"B·∫£n v∆∞∆°ng"
- Ê≠¶Âäü‚Üí"v√µ c√¥ng"; ËΩªÂäü‚Üí"khinh c√¥ng"; Ê±üÊπñ‚Üí"giang h·ªì"
- Â¢ÉÁïå‚Üí"c·∫£nh gi·ªõi"; ‰∏πËçØ‚Üí"ƒëan d∆∞·ª£c"; Ê≥ïÂÆù‚Üí"ph√°p b·∫£o"  
- Âìº‚Üí"H·ª´!"; ÂìéÂëÄ‚Üí"√îi tr·ªùi!"; Â§©Âïä‚Üí"Tr·ªùi ∆°i!"
- SFX: ËΩ∞‚Üí"B√ôMM!"; Á†∞‚Üí"ƒê·ª§C!"; ÂíîÂöì‚Üí"K·∫ÆC!" """

        elif source_lang == "ko":
            return """KO RULES:
- Jondaetmal‚Üí"·∫°/d·∫°"; banmal‚Üíb·ªè k√≠nh ng·ªØ
- Ìòï/ÎàÑÎÇò/Ïò§Îπ†/Ïñ∏Îãà‚Üí"anh/ch·ªã"; ÏÑ†Î∞∞‚Üí"ti·ªÅn b·ªëi" 
- ÏïÑÏù¥Í≥†‚Üí"√îi gi·ªùi!"; Ìóê‚Üí"H·∫£?!"; ÏôÄ‚Üí"Wow!"
- Îä•Î†•‚Üí"nƒÉng l·ª±c"; Í∞ÅÏÑ±‚Üí"th·ª©c t·ªânh"; Î†àÎ≤®ÏóÖ‚Üí"l√™n c·∫•p"
- SFX: ÏæÖ‚Üí"C·∫†CH!"; Ïøµ‚Üí"R·∫¶M!"; ÌúòÏùµ‚Üí"V·ª™N!" """

        else:
            return """GENERAL RULES:
- Ph√¢n bi·ªát formal/informal, nam/n·ªØ, gi√†/tr·∫ª
- C·∫£m th√°n: "·ªí!", "Tr·ªùi!", "Ch·∫øt ti·ªát!"
- Hi·ªáu ·ª©ng √¢m thanh: d·ªãch ph√π h·ª£p ti·∫øng Vi·ªát"""

    def _clean_gemini_response(self, response):
        """Enhanced cleaning to remove any AI explanations and return only translation"""
        if not response:
            return ""
            
        # Remove quotes and common prefixes
        cleaned = response.strip().strip('"').strip("'")
        
        # Remove translation labels
        prefixes_to_remove = [
            "B·∫£n d·ªãch:", "D·ªãch:", "Translation:", "Vietnamese:",
            "Ti·∫øng Vi·ªát:", "C√¢u d·ªãch:", "K·∫øt qu·∫£:", "ƒê√°p √°n:",
            "B·∫£n d·ªãch ti·∫øng Vi·ªát:", "Vietnamese translation:",
            "T√¥i s·∫Ω d·ªãch:", "ƒê√¢y l√† b·∫£n d·ªãch:", "C√¢u tr·∫£ l·ªùi:",
        ]
        
        for prefix in prefixes_to_remove:
            if cleaned.lower().startswith(prefix.lower()):
                cleaned = cleaned[len(prefix):].strip()
        
        # Split by common explanation indicators and take first part
        explanation_splits = [
            " (", "[", "Ho·∫∑c", "T√πy", "N·∫øu", "* ", "‚Ä¢ ",
            "- ", "Gi·∫£i th√≠ch:", "L∆∞u √Ω:", "Ch√∫ th√≠ch:",
            "C√≥ th·ªÉ", "Tu·ª≥ theo", "T√πy v√†o"
        ]
        
        for split_pattern in explanation_splits:
            if split_pattern in cleaned:
                parts = cleaned.split(split_pattern)
                if parts[0].strip():
                    cleaned = parts[0].strip()
                    break
        
        # Clean extra whitespace and newlines
        cleaned = " ".join(cleaned.split())
        
        # Final validation - if it contains typical AI response patterns, extract the core translation
        ai_patterns = [
            "c√≥ th·ªÉ d·ªãch", "t√πy ng·ªØ c·∫£nh", "tu·ª≥ theo", "ho·∫∑c l√†",
            "m·ªôt c√°ch kh√°c", "phi√™n b·∫£n kh√°c", "c√°ch kh√°c"
        ]
        
        for pattern in ai_patterns:
            if pattern in cleaned.lower():
                # Try to extract the first clean sentence before the pattern
                sentences = cleaned.split('.')
                if sentences and len(sentences[0]) > 3:
                    cleaned = sentences[0].strip()
                    break
                    
        return cleaned.rstrip('.,!?;:')

    def _preprocess_text(self, text):
        """Enhanced preprocessing for different comic types"""
        # Basic cleaning
        preprocessed_text = text.replace("Ôºé", ".")
        
        # Remove excessive whitespace
        preprocessed_text = " ".join(preprocessed_text.split())
        
        # Clean up common OCR artifacts
        preprocessed_text = preprocessed_text.replace("Ôºà", "(").replace("Ôºâ", ")")
        preprocessed_text = preprocessed_text.replace("ÔºÅ", "!").replace("Ôºü", "?")
        
        return preprocessed_text

    def _delay(self):
        time.sleep(random.randint(3, 5))
